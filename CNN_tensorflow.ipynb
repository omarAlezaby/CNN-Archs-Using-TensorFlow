{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport time\nimport csv\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/cifar10-comp\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#load images\ndata_x = np.load(\"../input/cifar10-comp/train_images.npy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87f6b14426841b06f408926204e8feacc00d777d"},"cell_type":"code","source":"data_x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cab4471684377e751f153614d122800dbfcdd52"},"cell_type":"code","source":"# make the channals tha last dim\ndata_x = data_x.transpose(0,3,2,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ff6039344acaa684cfb1aaf94630e0628d32cba"},"cell_type":"code","source":"print(data_x.shape)\nplt.imshow(data_x[20], interpolation='nearest')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b68f404eb74fa57ccabf4b1904dd5e0b5d298a9"},"cell_type":"code","source":"# categories of the classification\nlabels_i_s = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\nlabels_s_i = {cat:ind for ind, cat in enumerate(labels_i_s)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67e5579d69331a4a23495377517088567d6529dd"},"cell_type":"code","source":"labels_s_i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc8f14122401a4e80ed086d97d92a0ec97798e19"},"cell_type":"code","source":"# laod labels\ndata_y = np.genfromtxt(\"../input/cifar10-comp/train_labels.csv\", delimiter=',', dtype= str, skip_header=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b122e60b4b7245a5decaa577c9d4f27a0ae3712"},"cell_type":"code","source":"data_y = data_y[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a087c0ad20394bd3587c866890505a27b87fe333"},"cell_type":"code","source":"data_y[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2de36fe4423f4518736009471d5cd007b095c6f8"},"cell_type":"code","source":"# convert string labels to numeric\nlabels_num = np.zeros(data_y.shape, dtype=int)\nfor i, label in enumerate(data_y):\n    labels_num[i] = labels_s_i[label]\nprint(labels_num[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5669d40f6928061a9286b97aaf7e2c5c68fad694"},"cell_type":"code","source":"# convert numeric labels to one hot vector\none_hot_encoding = np.eye(10)[labels_num]\nprint(one_hot_encoding[0,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00c86e036480b0bc9c8b687389fd74aad209355f"},"cell_type":"code","source":"#normalize the images\ndata_x = data_x/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47b0ee5798f3b5cc43da429e33a60896b53eb9d9"},"cell_type":"code","source":"print(np.min(data_x))\nprint(np.max(data_x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91f7f793ea1ef33cef1c1fd1c7921d40fb3326a6"},"cell_type":"code","source":"# randomly shuffil the data\nidx = np.random.permutation(data_y.shape[0])\ndata_x,one_hot_encoding = data_x[idx], one_hot_encoding[idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2d46d4015fb47d183596af8a34cc10c8a18bf1e"},"cell_type":"code","source":"print(one_hot_encoding[21])\nplt.imshow(data_x[21], interpolation='nearest')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a99c3ed1485f0f5d55e0cb0d01b68478be1b475"},"cell_type":"code","source":"# divide the data set into traning and validation\nX_train = data_x\nX_valid = data_x[45000:]\ny_train = one_hot_encoding\ny_valid = one_hot_encoding[45000:]\nprint(X_train.shape)\nprint(X_valid.shape)\nprint(y_train.shape)\nprint(y_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b70773fe3553c888e37d101184e953a3449053c"},"cell_type":"code","source":"# CONV Layer \ndef Conv(input_data, num_input_chan, filter_size, num_filters, bias_init, name):\n    with tf.variable_scope(name) as scope:\n        # creat conv layer\n        #regularizer = tf.contrib.layers.l2_regularizer(scale=0.1)\n        layer = tf.layers.conv2d(inputs=input_data, filters=num_filters, kernel_size = [filter_size, filter_size]\n                                 , strides=[1, 1], padding='same', activation = \"relu\", use_bias = True)\n        return layer \n    \n'''\ndef Conv(input_data, num_input_chan, filter_size, num_filters, stride, name, pad = 'SAME'):\n    with tf.variable_scope(name) as scope:\n\n        # Create filters\n        filters = tf.get_variable('weghits', shape = [filter_size, filter_size, num_input_chan, num_filters])\n\n        # Create new biases\n        biases = tf.get_variable('bias', shape=[num_filters])\n\n        # creat conv layer\n        layer = tf.nn.conv2d(input=input_data, filter=filters, strides=[1, stride, stride, 1], padding=pad)\n\n        # Add bias \n        layer += biases\n\n        #Apply Activation\n        relu = tf.nn.relu(layer)\n        return layer \n    '''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f4df4601d5639039cb50582ad77a1d21f6190a5"},"cell_type":"code","source":"# MAXPOOL Layer\ndef Max_Pool(input_data, kernal_size, stride_size, name):\n    with tf.variable_scope(name) as scope:\n        layer = tf.layers.max_pooling2d(input_data, pool_size=[kernal_size, kernal_size], \n                               strides=[stride_size, stride_size],  padding=\"valid\")\n        return layer\n\n'''\ndef Max_Pool(input_data, kernal_size, stride_size, name):\n    with tf.variable_scope(name) as scope:\n        layer = tf.nn.max_pool(input_data, ksize=[1, kernal_size, kernal_size, 1], \n                               strides=[1, stride_size, stride_size, 1],  padding=\"VALID\")\n        return layer'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14a213ac9aa0598f72d41a80cd64e35054f3b9b6"},"cell_type":"code","source":"'''def FC(input_data, num_input, num_output, name):\n    with tf.variable_scope(name) as scope:\n        #intialize the weights \n        weights = tf.get_variable('weghits',shape = [num_input, num_output])\n        #intialize the bias \n        biases = tf.get_variable('bias', shape=[num_output])\n        # output Layer\n        layer =  tf.matmul(input_data, weights) + biases\n        return layer\n'''    \ndef FC(input_data, num_input, num_output, name):\n    with tf.variable_scope(name) as scope:\n        layer = tf.layers.dense(input_data, num_output)\n        return layer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3630b4465a6ba22523fc5812d4d76f1aae032dda"},"cell_type":"code","source":"'''#Network Archecture (ALexNet) \n#Faield\n\n#palceholder for input data\nx = tf.placeholder(tf.float32, shape=[None,32,32,3])\n#place holder \ny = tf.placeholder(tf.float32, shape=[None, 10])\ny_cls = tf.argmax(y, dimension=1)\n\n# first Layer (removed)\nconv1 = Conv(x, 3, 11, 96, 4, \"conv1\")\nnorm1 = tf.nn.local_response_normalization(conv1, depth_radius = 2, alpha = 1e-05, beta = 0.75, bias = 1.0, name = \"norm1\")\nmax_pool1 = Max_Pool(norm1, 3, 2, \"max_pool1\")\n# 2d layer\nconv2 = Conv(x, 3, 5, 256, 1, \"conv2\")\nnorm2 = tf.nn.local_response_normalization(conv2, depth_radius = 2, alpha = 1e-05, beta = 0.75, bias = 1.0, name = \"norm2\")\nmax_pool2 = Max_Pool(norm2, 3, 2, \"max_pool2\")\n\n# 3rd layer\nconv3 = Conv(max_pool2, 256, 3, 384, 1, \"conv3\")\n\n# 4th layer\nconv4 = Conv(conv3, 384, 3, 384, 1, \"conv4\")\n\n# 5th layer\nconv5 = Conv(conv4, 384, 3, 256, 1, \"conv5\")\nmax_pool5 = Max_Pool(conv5, 3, 2, \"max_pool5\")\n\n# Flatten the Max Layer\nflatten = tf.reshape(max_pool5, shape = [-1, max_pool5.shape[1]*max_pool5.shape[2]*max_pool5.shape[3]])\n\n#print(flatten.shape)\n\n# 6th layer\nfc1 = FC(flatten, int(flatten.shape[0]), 4096, \"fc1\")\nrelu_fc1 = tf.nn.relu(fc1)\ndropout_fc1 = tf.nn.dropout(relu_fc1, 0.5)\n\n# 7th layer\nfc2 = FC(dropout_fc1, 4096, 4096, \"fc2\")\nrelu_fc2 = tf.nn.relu(fc2)\ndropout_fc2 = tf.nn.dropout(relu_fc2, 0.5)\n\n# 7th layer\nfc3 = FC(dropout_fc1, 4096, 10, \"fc3\")'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68aff9055e33185426f4a088f8da299c3114d20e"},"cell_type":"code","source":"# archecture 2\n\nx = tf.placeholder(tf.float32, shape=[None, 32, 32, 3])\ny = tf.placeholder(tf.float32, shape=[None, 10])\ny_cls = tf.argmax(y, dimension=1)\n\nconv1 = Conv(x, 3, 3, 32, 0.0, \"conv1\")\nnorm1 = tf.layers.batch_normalization(conv1)\nrelu1 = tf.nn.relu(norm1)\n\nconv2 = Conv(relu1, 32, 3, 64, 0.0, \"conv2\")\nnorm2 = tf.layers.batch_normalization(conv2)\nrelu2 = tf.nn.relu(norm2)\n\nmax_pool1 = Max_Pool(relu2, 2, 2, \"max_pool1\")\n\nconv3 = Conv(max_pool1, 64, 3, 128, 0.0, \"conv3\")\nnorm3 = tf.layers.batch_normalization(conv3)\nrelu3 = tf.nn.relu(norm3)\n\nmax_pool2 = Max_Pool(relu3, 2, 2, \"max_pool2\")\n\n\nconv4 = Conv(max_pool2, 128, 3, 256, 0.0, \"conv4\")\nnorm4 = tf.layers.batch_normalization(conv4)\nrelu4 = tf.nn.relu(norm4)\n\nmax_pool3 = Max_Pool(relu4, 2, 2, \"max_pool3\")\n\nflat = tf.contrib.layers.flatten(norm4)\n\nfc1 = FC(flat, (int)(flat.shape[1]), 1024,\"fc1\")\nfc1_relu = tf.nn.relu(fc1)\nfc1_drop = tf.nn.dropout(fc1_relu, 0.7)\nnorm_fc1 = tf.layers.batch_normalization(fc1_drop)\n\nfc2 = FC(fc1_drop, 1024, 512,\"fc2\")\nfc2_relu = tf.nn.relu(fc2)\nfc2_drop = tf.nn.dropout(fc2_relu, 0.7)\nnorm_fc2 = tf.layers.batch_normalization(fc2_drop)\n\nfc3 = FC(fc2_drop, 512, 256,\"fc3\")\nfc3_relu = tf.nn.relu(fc3)\nfc3_drop = tf.nn.dropout(fc3_relu, 0.7)\nnorm_fc3 = tf.layers.batch_normalization(fc3_drop)\n\nfc4 = FC(norm_fc3, 256, 10,\"fc4\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7871028303534accd76d79c1445d0517409658a"},"cell_type":"code","source":"# the prediction \nwith tf.variable_scope(\"Softmax\") as scope:\n    y_pred = tf.nn.softmax(fc4)\n    y_pred_cls = tf.argmax(y_pred, dimension=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18af319efc6fd718aaf30864d391eaf3dad789a0"},"cell_type":"code","source":"# calculate the loss\n#L2_loss = tf.losses.get_regularization_loss()\nloss = tf.nn.softmax_cross_entropy_with_logits(logits=fc4, labels=y)\n#calculate cost\ncost = tf.reduce_mean(loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df45c43059a96214f72cbce50dd86801e9d7ddda"},"cell_type":"code","source":"# set optimizer \nlearning_rate = tf.placeholder(tf.float32, shape=[])\noptimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3d6b31c3f2539a40279ced5ede5f9a31a5a1ba8"},"cell_type":"code","source":"# accurcy\ncorrect_pred = tf.equal(y_cls, y_pred_cls)\naccurcy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae33fb2fce8db2e0d18ed512539c75047fca4baf"},"cell_type":"code","source":"# runing variables\nnum_epoch = 100\nnum_patch = 128\ntrain_accurses = []\nvalid_accurses = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"772b2634753699fd6624857d8dea53414ef4f94c"},"cell_type":"code","source":"test_data = np.load(\"../input/cifar10-comp/test_images.npy\")\ntest_data = test_data.transpose(0,3,2,1)\ntest_data = test_data / 255\nprint(test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5deb59e9f45a819084d7428e49113d3eb061e8d5","scrolled":true},"cell_type":"code","source":"init_lr = .001\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for epoch in range(1, num_epoch):\n        start_time = time.time()\n        train_acc = 0\n        #random shuffel the training data\n        idx = np.random.permutation(X_train.shape[0])\n        X_train,y_train = X_train[idx], y_train[idx]\n        #iterate for batches\n        for step in range(int(X_train.shape[0]/num_patch)):\n            #print(str(step*num_patch) +\"  \"+str((step+1)*num_patch))\n            x_batch, y_batch = X_train[step*num_patch:(step+1)*num_patch], y_train[step*num_patch:(step+1)*num_patch] \n            # update varib\n            sess.run(optimizer, feed_dict = {x: x_batch, y: y_batch, learning_rate: init_lr})\n            train_acc += sess.run(accurcy, feed_dict = {x: x_batch, y: y_batch, learning_rate: init_lr})\n        end_time = time.time()\n        train_acc /= int(X_train.shape[0]/num_patch)\n        train_accurses.append(train_acc)\n        valid_acc = sess.run(accurcy, feed_dict = {x: X_valid, y: y_valid})\n        valid_accurses.append(valid_acc)\n        print(\"Epoch \"+str(epoch+1)+\" completed : Time usage \"+str(int(end_time-start_time))+\" seconds\")\n        print(\"\\tAccuracy:\")\n        print (\"\\t- Training Accuracy:\\t{}\".format(train_acc))\n        print (\"\\t- Validation Accuracy:\\t{}\".format(valid_acc))\n        if(epoch%10==0):  init_lr /= 2\n            \n            \n    # test \n    labelsss = []\n    for i in test_data:\n        i =  i.reshape(1,32,32,3)\n        test_labels = sess.run(y_pred_cls, {x: i})\n        labelsss.append((int)(test_labels))\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32c0c40cbc5a9eedaf42e88f15420c90fd7301c5"},"cell_type":"code","source":"labelsss[3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f05b5c6fdaef89c2e81e9878906080d1f5f5c249"},"cell_type":"code","source":"with open('test_labels.csv', mode='w') as test:\n    test_writer = csv.writer(test, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n\n    test_writer.writerow(['Id', 'Category'])\n    for inx,label in enumerate(labelsss):\n        test_writer.writerow([inx+1, labels_i_s[label]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71e0be7250896a5d9d21108f93840e303ac80929"},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"044342babadb2c1a893968d6dcb94f5bcd12c8e3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}